# -*- coding: utf-8 -*-
"""Automation inspection (segmentation)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oARCxGJnCW-Zruyhn1aWEdGgf-o9YEkg
"""

from google.colab import drive
drive.mount('/content/drive')

# необходимые модули
import torch
import random
import numpy as np
import pandas as pd
import json
import base64
import os
import pylab
import torchvision
import shutil
import matplotlib.pyplot as plt
from torchvision import transforms, models
from tqdm import tqdm
import cv2
import pylab
from google.colab.patches import cv2_imshow
random.seed(0)
np.random.seed(0)
torch.manual_seed(0)
torch.cuda.manual_seed(0)
torch.backends.cudnn.deterministic = True

train_dir = '/content/drive/MyDrive/hac2021/train'
test_dir='/content/drive/MyDrive/hac2021/test'

!rm -rf 'train_png'
!rm -rf 'val_png'
os.makedirs('/content/train_png')
os.makedirs('/content/val_png')
os.makedirs('/content/train_png/image')
os.makedirs('/content/train_png/mask')
os.makedirs('/content/val_png/image')
os.makedirs('/content/val_png/mask')

# number_train_photo=int(len(os.listdir(train_dir))/2)
# FILE_FILTER=['.png','.json']
# for index in range(1,number_train_photo+1): 
#     if index<10:
#       number="00{index}".format(index=index)
#       current='/content/drive/My Drive/dataset_its/train/'+number
#       print(current)
#     elif index<100 and index>=10:
#       number="0{index}".format(index=index)
#       current='/content/drive/My Drive/dataset_its/train/'+number
#       print(current)
#     elif index>=100:
#       number='{index}'.format(index=index)
#       current='/content/drive/My Drive/dataset_its/train/'+number
#       print(current)

#     with open(current+FILE_FILTER[1], 'r', encoding='utf-8') as fh: #открываем файл на чтение
#       data = json.load(fh) #загружаем из файл а данные в словарь data
#       class_photo=data['shapes'][0]['label']
#       train_path='/content/train/'+'{path}/'.format(path=class_photo)
#       train_png_path='/content/train_png'
#       train_json_path='/content/train_json'
#       shutil.copy(train_dir+number+FILE_FILTER[0], train_png_path)
#       shutil.copy(train_dir+number+FILE_FILTER[1], train_json_path)

# gpuid=0
# if(torch.cuda.is_available()):
#     print(torch.cuda.get_device_properties(gpuid))
#     torch.cuda.set_device(gpuid)
#     device = torch.device(f'cuda:{gpuid}')
# else:
#     device = torch.device(f'cpu')

val_part=6
number_train_photo=int(len(os.listdir(train_dir))/2)
iter=0
for image in sorted(os.listdir(train_dir+'/image')):
  if iter%val_part!=0:
    shutil.copy(train_dir+'/image/'+image,'/content/train_png/image')
  else:
    shutil.copy(train_dir+'/image/'+image,'/content/val_png/image')   
  iter+=1
iter=0
for mask in sorted(os.listdir(train_dir+'/mask')):
  if iter%val_part!=0:
    shutil.copy(train_dir+'/mask/'+mask,'/content/train_png/mask')
  else:
    shutil.copy(train_dir+'/mask/'+mask,'/content/val_png/mask')  
  iter+=1

# val_part=20
# number_train_photo=int(len(os.listdir(train_dir))/2)
# FILE_FILTER=['.png']
# for index in range(1,number_train_photo+1): 
#     if index<10:
#       number="00{index}".format(index=index)
#       current='/content/drive/My Drive/dataset_its/train/'+number
#       print(current)
#     elif index<100 and index>=10:
#       number="0{index}".format(index=index)
#       current='/content/drive/My Drive/dataset_its/train/'+number
#       print(current)
#     elif index>=100:
#       number='{index}'.format(index=index)
#       current='/content/drive/My Drive/dataset_its/train/'+number
#       print(current)

#     if index%val_part!=0:
#       train_png_path='/content/train_png'
#       train_json_path='/content/train_json'
#       shutil.copy(train_dir+number+FILE_FILTER[0], train_png_path)
#       shutil.copy(train_dir+number+FILE_FILTER[1], train_json_path)
#     else:
#       val_png_path='/content/val_png'
#       val_json_path='/content/val_json'
#       shutil.copy(train_dir+number+FILE_FILTER[0], val_png_path)
#       shutil.copy(train_dir+number+FILE_FILTER[1], val_json_path)

# train_json_path='/content/train_json/'
# val_json_path='/content/val_json/'
# json_path=[train_json_path, val_json_path]
# train_mask=[]
# val_mask=[]
# for path in json_path:
#   for filename in sorted(os.listdir(path)):
#       with open(os.path.join(path, filename), 'r') as f:
#         layout = json.load(f)
#       h, w = layout['imageHeight'], layout['imageWidth']
#       true_mask = np.zeros((h, w), np.uint8)
#       label = layout['shapes'][0]['label']
#       for shape in layout['shapes']:
#         polygon = np.array([point[::-1] for point in shape['points']])
#         cv2.fillPoly(true_mask, [polygon[:, [1, 0]]], 255)
#       # cv2_imshow(true_mask)
#       if path==train_json_path:
#         train_mask.append(true_mask)
#       else:
#         val_mask.append(true_mask)
# train_mask=np.array(train_mask)
# val_mask=np.array(val_mask)

dataname="defect_area"
ignore_index = -100 
gpuid=0

# --- unet params

n_classes= 1    #number of classes in the data mask that we'll aim to predict
in_channels= 3  #input channel of the data, RGB = 3
padding= True   #should levels be padded
depth= 2      #depth of the network 
wf= 4           #wf (int): number of filters in the first layer is 2**wf, was 6
up_mode= 'upsample' #should we simply upsample the mask, or should we try and learn an interpolation 
batch_norm = True #should we use batch normalization between the layers

# --- training params
batch_size=8
patch_size=500
num_epochs = 50
edge_weight = 1.1 
phases = ["train","val"] #how many phases did we create databases for?
validation_phases= ["val"] #when should we do valiation? note that validation is time consuming, so as opposed to doing for both training and validation, we do it only for vlaidation at the end of the epoch

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, datasets, models


from unet import UNet #code borrowed from https://github.com/jvanvugt/pytorch-unet

import PIL
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import cv2

import numpy as np
import sys, glob

# from tensorboardX import SummaryWriter

import scipy.ndimage 

import time
import math
import tables

import random

from sklearn.metrics import confusion_matrix

if(torch.cuda.is_available()):
    print(torch.cuda.get_device_properties(gpuid))
    torch.cuda.set_device(gpuid)
    device = torch.device(f'cuda:{gpuid}')
else:
    device = torch.device(f'cpu')

train_png_path='/content/train_png/image/'
val_png_path='/content/val_png/image/'
png_path=[train_png_path, val_png_path]
train_set=[]
val_set=[]
iter=0
for path in png_path:
  for file in sorted(os.listdir(path)):
    iter+=1
    image = cv2.imread(path+'{file}'.format(file=file))
    # image_rgb = image.astype(np.uint8)
    if path==train_png_path:
      train_set.append(image) 
    else:
      val_set.append(image)
train_set=np.array(train_set)
val_set=np.array(val_set)

train_png_path='/content/train_png/mask/'
val_png_path='/content/val_png/mask/'
png_path=[train_png_path, val_png_path]
train_mask=[]
val_mask=[]
iter=0
for path in png_path:
  for file in sorted(os.listdir(path)):
    iter+=1
    image = cv2.imread(path+'{file}'.format(file=file),0)
    # image_rgb = image.astype(np.uint8)
    if path==train_png_path:
      train_mask.append(image) 
    else:
      val_mask.append(image)
train_mask=np.array(train_mask)
val_mask=np.array(val_mask)

print(len(train_set))
print(len(train_mask))

cv2_imshow(train_set[10])
cv2_imshow(train_mask[10])

print(train_set.shape)
print(train_mask.shape)
print(val_set.shape)
print(val_mask.shape)

class SimDataset(Dataset):
  def __init__(self, input_image, input_mask=None, transform_image=None, transform_mask=None):
    self.transform_image = transform_image
    self.transform_mask=transform_mask
    self.input_images = input_image
    self.target_masks = input_mask


  def __len__(self):
    return len(self.input_images)

  def __getitem__(self, idx):
    image = self.input_images[idx]
    if self.target_masks is not None:
      mask = self.target_masks[idx]
    if self.transform_image is not None:
      image = self.transform_image(image)
    if self.transform_mask is not None:
      mask=self.transform_mask(mask)
    if self.target_masks is not None:
      return [image, mask]
    else:  
      return image

# use the same transformations for train/val in this example
trans = transforms.Compose([
  # transforms.ToPILImage(),
  # transforms.Resize(800),
  # transforms.ToTensor()
  # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet
])
img_transform = transforms.Compose([
                                    


     transforms.ToPILImage(),

    # transforms.RandomVerticalFlip(),
    # transforms.RandomHorizontalFlip(),
    # transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color
    # transforms.RandomResizedCrop(size=patch_size),
    # transforms.RandomRotation(180),
    # transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=.5),
    # transforms.RandomGrayscale(),
    transforms.Resize((500,500)),
    transforms.ToTensor()
    ])

mask_transform = transforms.Compose([
    transforms.ToPILImage(),
    # transforms.RandomVerticalFlip(),
    # transforms.RandomHorizontalFlip(),
    # transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color
    # transforms.RandomResizedCrop(size=patch_size,interpolation=PIL.Image.NEAREST),
    # transforms.RandomRotation(180),
    transforms.Resize((500,500)),
    transforms.ToTensor()
    ])
train_dataset = SimDataset(train_set,train_mask, transform_image = img_transform, transform_mask = mask_transform)
val_dataset = SimDataset(val_set,val_mask, transform_image = img_transform, transform_mask=mask_transform)

# batch_size = 25
image_datasets = {
  'train': train_set, 'val': val_set
}

dataloaders = {
  'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0),
  'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
}

# img_transform = transforms.Compose([
#      transforms.ToPILImage(),
#     transforms.RandomVerticalFlip(),
#     transforms.RandomHorizontalFlip(),
#     transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color
#     transforms.RandomResizedCrop(size=patch_size),
#     transforms.RandomRotation(180),
#     transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=.5),
#     transforms.RandomGrayscale(),
#     transforms.ToTensor()
#     ])


# mask_transform = transforms.Compose([
#     transforms.ToPILImage(),
#     transforms.RandomVerticalFlip(),
#     transforms.RandomHorizontalFlip(),
#     transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), #these need to be in a reproducible order, first affine transforms and then color
#     transforms.RandomResizedCrop(size=patch_size,interpolation=PIL.Image.NEAREST),
#     transforms.RandomRotation(180),
#     ])

# import torch
# import torch.optim as optim
# from torch.optim import lr_scheduler
# import time
# import copy

# device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# print(device)

# num_class = 6
# model = ResNetUNet(num_class).to(device)

# # freeze backbone layers
# #for l in model.base_layers:
# #    for param in l.parameters():
# #        param.requires_grad = False

# optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)

# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)

# model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)

model = UNet(n_classes=n_classes, in_channels=in_channels, padding=padding,depth=depth,wf=wf, up_mode=up_mode, batch_norm=batch_norm).to(device)
print(f"total params: \t{sum([np.prod(p.size()) for p in model.parameters()])}")

import torch
import torch.nn as nn

def dice_loss(pred, target, smooth = 1.):
    pred = pred.contiguous()
    target = target.contiguous()    

    intersection = (pred * target).sum(dim=2).sum(dim=2)
    
    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))
    
    return loss.mean()

from collections import defaultdict
import torch.nn.functional as F

def calc_loss(pred, target, metrics, bce_weight=0.5):
    bce = F.binary_cross_entropy_with_logits(pred, target)

    pred = F.sigmoid(pred)
    dice = dice_loss(pred, target)

    loss = bce * bce_weight + dice * (1 - bce_weight)

    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)
    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)
    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)

    return loss

def print_metrics(metrics, epoch_samples, phase):
    outputs = []
    for k in metrics.keys():
        outputs.append("{}: {:4f}".format(k, metrics[k] / epoch_samples))

    print("{}: {}".format(phase, ", ".join(outputs)))

def train_model(model, optimizer, scheduler, num_epochs=25):
    best_model_wts = copy.deepcopy(model.state_dict())
    best_loss = 1e10

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        since = time.time()

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                scheduler.step()
                for param_group in optimizer.param_groups:
                    print("LR", param_group['lr'])

                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            metrics = defaultdict(float)
            epoch_samples = 0

            for inputs, labels in dataloaders[phase]:

                inputs = inputs.to(device)
                labels = labels.to(device)
                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)

                    loss = calc_loss(outputs, labels, metrics)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                epoch_samples += inputs.size(0)

            print_metrics(metrics, epoch_samples, phase)
            epoch_loss = metrics['loss'] / epoch_samples
            # deep copy the model
            if phase == 'val' and epoch_loss < best_loss:
                print("saving best model")
                best_loss = epoch_loss
                best_model_wts = copy.deepcopy(model.state_dict())

        time_elapsed = time.time() - since
        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))

    print('Best val loss: {:4f}'.format(best_loss))
    # load best model weights
    model.load_state_dict(best_model_wts)
    return model

import torch
import torch.optim as optim
from torch.optim import lr_scheduler
import time
import copy
optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)

exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)

model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=300)

torch.save(model, '/content/segmentation_model.txt')



test_png_path='/content/val_png/image/'
test_set=[]
iter=0
for file in sorted(os.listdir(test_png_path)):

    iter+=1
    image = cv2.imread(test_png_path+'{file}'.format(file=file))
    # image_rgb = image.astype(np.uint8)
    test_set.append(image)
test_set=np.array(test_set)

import math

model.eval()   # Set model to the evaluation mode
# Create another simulation dataset for test
test_dataset = SimDataset(input_image=test_set,transform_image = img_transform)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
val_dataset = SimDataset(input_image=val_set,transform_image = img_transform)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

def reverse_transform(inp):
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    inp = (inp * 255).astype(np.uint8)

    return inp

test_img_paths = []
# for inputs , labels in dataloaders['train']:
#     print(type(inputs))
#     inputs = inputs.to(device)
#     labels = labels.to(device)
iter=0
test_val_dataloaders=[test_dataloader,val_dataloader]
flag_test_val=test_val_dataloaders[0]
mask_base64_array=[]
for inputs in flag_test_val:
    inputs = inputs.to(device)
    print(inputs[0].cpu().numpy())
    cv2_imshow(reverse_transform(inputs[0].cpu()))
    print('inputs',inputs.shape)
    outputs = model(inputs)
    outputs = F.sigmoid(outputs)
    outputs = outputs.data.cpu().numpy()
    for output in outputs:
      print(outputs.shape)
      print(outputs[0].shape)
      output = np.transpose(output, (1,2,0))
      # print(outputs.shape)
      # outputs=np.squeeze(outputs, axis = 0) 
      # print(outputs.shape)
      output = ((output - output.min()) * (1/(output.max() - output.min()) * 255)).astype('uint8')
      # outputs.save('my_f.png')
      # print(outputs)
      # Change channel-order and make 3 channels for matplot
      # input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]
      # cv2_imshow(input_images_rgb[0])
      ret,mask = cv2.threshold(output,150,255,cv2.THRESH_BINARY)
      # cv2_imshow(output)
      cv2_imshow(mask)
      cv2.imwrite('/content/current.png', mask)
      with open("/content/current.png", "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read())
        new_encoded_string=encoded_string.decode('utf-8')
        mask_base64_array.append(new_encoded_string)
    # print(outputs)
    # img = Image.fromarray(outputs, 'RGB')
    # img.save('my.png')
    # test_predictions.append(
    #     torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())
    # test_predictions_arg.append(preds.argmax(dim=1).data.cpu().numpy())
    # test_img_paths.extend(paths)

if flag_test_val==test_dataloader:
  test_submission = pd.DataFrame.from_dict({'base64 encoded PNG (mask)':mask_base64_array})
  test_submission.to_csv('test_submission.csv')

else:
  val_submission=pd.read_csv('/content/val_submission.csv')
  val_submission['base64 encoded PNG (mask)']=mask_base64_array
  val_submission.to_csv('val_submission.csv')
  print(val_submission.head())
# base64_submission_df = pd.DataFrame.from_dict({'base64 encoded PNG (mask)':mask_base64_array})
# print(base64_submission_df.head(n=20))

# метрика
LABELS = ['c_kefir', 'ent_cloacae', 'klebsiella_pneumoniae', 'moraxella_catarrhalis',
          'staphylococcus_aureus', 'staphylococcus_epidermidis']
DATASET_PATH = '/content/val_json'
label_metrics = np.zeros((len(LABELS), len(LABELS)), int)
seg_metrics = []
df = pd.read_csv('val_submission.csv')
def set_metrics(filename):
      global label_metrics, seg_metrics, df

      with open(os.path.join(DATASET_PATH, filename), 'r') as f:
          layout = json.load(f)

      h, w = layout['imageHeight'], layout['imageWidth']
      true_mask = np.zeros((h, w), np.uint8)
      label = layout['shapes'][0]['label']

      for shape in layout['shapes']:
          polygon = np.array([point[::-1] for point in shape['points']])
          cv2.fillPoly(true_mask, [polygon[:, [1, 0]]], 255)

      ind = int((int(filename[:-len(FILE_FILTER[1])])-1)/val_part)
      new_label = df.at[ind, 'class']
      label_metrics[LABELS.index(new_label)][LABELS.index(label)] += 1

      with open('tmp_bacteria.png', 'wb') as fp:
          fp.write(base64.b64decode(df.at[ind, 'base64 encoded PNG (mask)'].encode()))
      mask = cv2.imread('tmp_bacteria.png', 0)
      seg_metrics += [np.count_nonzero(np.logical_and(true_mask, mask)) /
                      np.count_nonzero(np.logical_or(true_mask, mask))]
def calculate_metrics():
      # print(seg_metrics)
      mean_iou = np.mean(seg_metrics)
      precisions = dict.fromkeys(LABELS, 0.)
      for label in LABELS:
          i = LABELS.index(label)
          precisions[label] = label_metrics[i][i] / np.sum(label_metrics[i, :])
      mean_precision = np.mean(list(precisions.values()))

      score = mean_iou + np.sum(list(precisions.values()))

      print(f'mean_iou: {mean_iou}')
      for k, v in precisions.items():
          print(f'precision_{k}: {v}')
      print(f'mean_precision: {mean_precision}\nscore: {score}')


def main():
      files = os.listdir(DATASET_PATH)
      for file in sorted(filter(lambda x: x[-len(FILE_FILTER[1]):].lower() == FILE_FILTER[1], files)):
          set_metrics(file)
      calculate_metrics()


main()

kefir=seg_metrics[0:14]
cloacae=seg_metrics[14:31]
kleb=seg_metrics[31:34]
catarr=seg_metrics[34:42]
aur=seg_metrics[42:46]
epid=seg_metrics[46:51]

print('kefir',np.mean(kefir))
print('cloacae',np.mean(cloacae))
print('kleb',np.mean(kleb))
print('catarr',np.mean(catarr))
print('aur',np.mean(aur))
print('epid',np.mean(epid))